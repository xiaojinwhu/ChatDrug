{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'？\\n\\n是的，银行是一个安全的地方来存放财产，它们有严格的安全措施来保护客户的财产。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"把我的一个亿存在银行安全吗\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "？\n",
       "\n",
       "是的，银行是一个安全的地方来存放财产，它们有严格的安全措施来保护客户的财产。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(llm(\"把我的一个亿存在银行安全吗\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained large language models (LLMs) are widely used in many sub-fields of\n",
      "natural language processing (NLP) and generally known as excellent few-shot\n",
      "learners with task-specific exemplars. Notably, chain of thought (CoT)\n",
      "prompting, a recent technique for eliciting complex multi-step reasoning\n",
      "through step-by-step answer examples, achieved the state-of-the-art\n",
      "performances in arithmetics and symbolic reasoning, difficult system-2 tasks\n",
      "that do not follow the standard scaling laws for LLMs. While these successes\n",
      "are often attributed to LLMs' ability for few-shot learning, we show that LLMs\n",
      "are decent zero-shot reasoners by simply adding \"Let's think step by step\"\n",
      "before each answer. Experimental results demonstrate that our Zero-shot-CoT,\n",
      "using the same single prompt template, significantly outperforms zero-shot LLM\n",
      "performances on diverse benchmark reasoning tasks including arithmetics\n",
      "(MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin\n",
      "Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled\n",
      "Objects), without any hand-crafted few-shot examples, e.g. increasing the\n",
      "accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with\n",
      "large InstructGPT model (text-davinci-002), as well as similar magnitudes of\n",
      "improvements with another off-the-shelf large model, 540B parameter PaLM. The\n",
      "versatility of this single prompt across very diverse reasoning tasks hints at\n",
      "untapped and understudied fundamental zero-shot capabilities of LLMs,\n",
      "suggesting high-level, multi-task broad cognitive capabilities may be extracted\n",
      "by simple prompting. We hope our work not only serves as the minimal strongest\n",
      "zero-shot baseline for the challenging reasoning benchmarks, but also\n",
      "highlights the importance of carefully exploring and analyzing the enormous\n",
      "zero-shot knowledge hidden inside LLMs before crafting finetuning datasets or\n",
      "few-shot exemplars.\n",
      "Large Language Models are Zero-Shot Reasoners\n"
     ]
    }
   ],
   "source": [
    "paper = next(arxiv.Search(id_list=[\"2205.11916\"], max_results=1).results())\n",
    "print(paper.summary)\n",
    "print(paper.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_path = paper.download_pdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./2205.11916v4.Large_Language_Models_are_Zero_Shot_Reasoners.pdf'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(paper_path)\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"\\n\\n\".join([page.page_content for page in pages[0:2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm(\n",
    "    f\"\"\"\n",
    "               这里有一个论文的前两页:\n",
    "               {content}\n",
    "               基于这个内容，回答 什么是zero-shot chain-of-thought prompting?\n",
    "               \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Zero-shot chain-of-thought prompting (Zero-shot-CoT) 是一种技术，旨在通过提供一个简单的提示来帮助大型语言模型（LLMs）实现零点学习，从而实现复杂的多步推理。它通过在每个答案之前添加“让我们一步一步思考”的提示，来帮助模型产生一个可行的推理路径，从而在零点方法失败的情况下达到"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
